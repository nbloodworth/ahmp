# A collection of classes and subroutines for creating and interfacing with the HLA structural database
# ================================================================================

def help_msg():
    return '''
 MHC_database is a class with a collection of methods and attributes used
 create and access information contained within a database of all HLA
 allele sequences and known structures. The class is designed to facilitate
 computational modeling of peptide-MHC structures with downstream
 applications (such as Rosetta or py.Rosetta)

 ============================PYTHON DEPENDENCIES============================
 BioPython
 Pandas
 Requests
 Formats (custom class in same folder as HLA_db.py)

 ==========================DATABASE FILE STRUCTURE==========================
 *All .info files are .csv files organized by column:value format and can
 be read into a pandas dataframe

 Database folder/file------->Description
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 >MHC_Database/------------->Parent folder
 |-->build/----------------->Folder containing files important for database
    |                        build
    |-->allele_list.info---->File containing full sequences for each allele,
    |                        the allele the sequence belongs to, and a list
    |                        of alleles with at least one PDB to use as
    |                        templates (in order of sequence identity). The
    |                        templates list is time consuming to create and
    |                        is made "as needed", and afterwards the
    |                        templates list is saved to this file so it
    |                        won't need to be created again if necessary.
    |-->allele_seq.info ---->File with all unique alpha1/alpha2 domain
    |                        sequences for every HLA allele, and a list of
    |                        HLA alleles with that sequence. Used for
    |                        building receptor models with AlphaFold2.
    |-->mhc_3d_assays.csv--->CSV file from IEDB with list of PDBs and PDB
    |                        info for all MHC models
    |-->tcr_3d_assays.csv--->CSV file from IEDB with list of PDBs and PDB
    |                        info for all TCR/MHC models
 |-->templates/------------->Folder containing all PDB templates for all
 |                           MHC alleles
 |-->default_receptor/------>Folder containing PDBs to use as receptors for
 |                           peptide modeling (generated by AlphaFold2 when
 |                           self.build_receptor() method is called)
 |-->database.info---------->File containing a summary of all MHC/peptide
                             PDB structures in database.
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

 ==========================CLASSES AND SUBROUTINES==========================

 [class] chainSelect
 Overloads default Select class in Biopython's PDBIO module to allow
 selection of chains with MHC-I and peptide antigen. Also removes HETATMs.
 Called by self.build() method

 [class] MHCdatabase
    Creates an instance of the MHC database. From this instance further
    subroutines can be called, and properties inferred.
 ---------------------------------------------------------------------------
    [attribute] locate
       Location of database; can be set with constructor.
    [attribute] [hidden] __LOCATE__
       Default location of database. Defaults to
       /home/<user>/Data/MHC_database.
    [attribute] allele
       The allele that the MHC database object is currently pointed towards.
    [attribute] template
       The allele, present in the database, that will be used as a template
       for peptide backbone threading.
  ---------------------------------------------------------------------------
    [method] __init__
      Constructor for a database object. Optionally takes in database
      location if different from default (/home/usr/Data/MHC_database/), an
      option to set the allele and/or template, and an option to build the
      database if it does not exist.
  ---------------------------------------------------------------------------
     [method] build(allele_list=None)
       Builds the database at location specified by self.locate. If
       self.locate does not exist, will make the folder and parents.
  ---------------------------------------------------------------------------
     [method] set_allele(check_allele, get_templates=True,
                 build_receptor=True)
        Sets an allele for the database instance. Prints a warning and
        returns False if allele requested does not exist. Also sets allele
        structural templates if no structure for the allele is available,
        and builds a receptor model with AlphaFold2 if one is not already
        created (optional).
  ---------------------------------------------------------------------------
     [method] query_mhc_database(allele="all", quiet=False, getpdb=False,
                 getepitopes=False, gettemplate=False)
        Method for retrieving information from the database. Variable
        behavior depending on which option is set by the user, but always
        returns a tuple with the first element corresponding to a data
        structure (list or dict) and the second a boolean. Outputs for each
        option are below in priority order:

        allele="all": Returns a list of all available alleles (default
        behavior). Returns a True value if the value for
        MHCdatabase().allele is present in database.info

        allele="<some HLA here>": Returns a list of all available alleles
        and a boolean value indicating whether or not requested allele is
        present (True) or absent (False) (ignores the value for
        MHCdatabase().allele for the purpose of this output)

        getpdb=True: Prints and returns a list of PDBs with templates for
        MHCdatabase().allele. If no allele value set for database instance,
        will return all PDBs belonging to the variable allele. If that
        variable is set to the default ("all"), then will return all PDBs
        in database. If no PDBs are found, also returns False.

        getepitopes=True: Returns a dictionary where each key corresponds
        to a PDB ID in the database belonging to the allele assigned to
        the database instance (MHCdatabase().allele), and the value is the
        epitope sequence. If MHCdatabase().allele is set to None, returns
        all PDB:epitope sequences in the database. If no PDBs for the
        allele in quesiton are found, returns False.

        gettemplate=<4-letter-PDB-code>: Returns a dictionary where each
        key corresponds to database.info column values for a given PDB in
        the database, and a boolean indicating whether or not the PDB was
        found. Keys include:
        'Epitope_IRI', 'Epitope_Description', 'MHC_Allele',
        'MHC_PDB_Chain1', 'Antigen_PDB_Chain(s)', 'PDB_ID',
        'Resolution_(Angstrom)', 'Epitope_ID'
        If the PDB is not found in the database, returns an empty dict and
        False.

        quiet=True: Supress the printing of execution info to screen by
        setting quiet=True
  ---------------------------------------------------------------------------
     [method] fetch_mhc_allele_info(allele_list=None, update=False)
        Fetches a list of all MHC alleles and sequences available in either
        a provided fasta file (optional argument allele_list=<filename or
        URL>) or the IMGT database. Writes the allele_list.info and
        allele_seq.info files in MHC_database/build/.
  ---------------------------------------------------------------------------
     [method] set_mhc_templates()
        Method for setting the allele templates, if self.allele is not
        present in the MHC structure database. Otherwise,
        self.template=self.allele.
  ---------------------------------------------------------------------------
     [method] trim_seq(seq, HLA_allele)
        Method that takes in an HLA sequence and allele and returns the
        alpha 1 and alpha 2 domains only to build a receptor model.
  ---------------------------------------------------------------------------
     [method] build_receptor(overwrite=False,
                 AF2_MINICONDA="/sb/apps/alphafold211/miniconda3",
                 AF2_DATADIR="/sb/apps/alphafold-data",
                 AF2_REPO="/sb/apps/alphafold211/alphafold")
        Wrapper for a call to AlphaFold2 to build the MHC receptor based on
        the trimmed alpha 1 and alpha 2 domain(s). AF2_MINICONDA refers to
        the location of the local installation of the AlphaFold2 conda
        environment; AF2_DATADIR refers to the local AlphaFold2 database,
        and AF2_REPO refers to the local AlphaFold2 repository.
 ---------------------------------------------------------------------------
     [method] get_peptide_template(self, query_sequence, method="best",
                 cutoff=0, omit=["self"]):
        Method to retrieve a structure from the database whose peptide
        backbone sequence matchest that of query_sequence. Returns the PDB
        code that corresponds to the matching structure in
        <database>/templates. If execution fails, returns False.

        Description of method variables:
        query_sequence: the sequence we are looking to find a template for
        method:   The method to perform the match (string). Options include:
          "best":      [default] Finds the best matching template by
                       alignment similarity score using a BLOSUM62 matrix for
                       AA evolutionary similarity
          "worst":     As above, but returns the template with the worst
                       score
          "bestabove": Finds the best matching template by %% identity above
                       a threshold given by the variable 'cutoff'. Does not
                       consider evolutionary similarity between AA
          "worstbelow":Finds the worst matching template by %% identity
                       below a threshold given by the variable 'cutoff'
        cutoff:   Set a value between 0 and 1 that indicates a threshold for
                  sequence identity for "bestabove" and "worstbelow"
                  methods.
        omit:     A list of PDB templates to omit from template selection
                  (4-character PDB codes). If "self" is included in the
                  list, any template with a 100% matching sequence will be
                  ignored.
 ---------------------------------------------------------------------------
     [method] help()
        Prints this help message and exits.

 =============================USE AND EXAMPLES==============================
  Use examples:

 #Example 0: Print these usage instructions:

    from HLA_db import MHCdatabase
    MHCdatabase().help()

    >MHC_database is a class with a collection of methods and attributes
    >used create a and access information contained within a database of
    >all HLA allele sequences and known structures. The class is designed
    ...

 #Example 1: Create an instance of the database: (note: will NOT build
             database or assign an allele to the instance unless specified
             by user)

     from HLA_db import MHCdatabase
     db=MHCdatabase()

 #Example 2: Build the database:

     db.locate="/home/user/database-location" #Optionaly specify location
    db.build()

 #Example 3: List all alleles with structural templates in database:

    allele_list=db.query_mhc_database(quiet=True)
    print(allele_list[0])

    >['A*01:01', 'A*02:01', 'A*02:03', 'A*02:06'...]

 #Example 4: Assign an allele to the database instance and initiate query:

    print(db.allele) #Before assigning an allele, the default value is None

    >None

    db.set_allele("A*02:01", get_templates=False, build_receptor=False)
    print(db.allele)

    >A*02:01 #Value is a string with format <gene>*<allele group>:<protein>

 #Example 5: Retrieve all PDBs in the database matching this allele:

    pdb_list=db.query_mhc_database(quiet=True, getpdb=True)
    print(pdb_list[0])

    >['3MRE', '3MRG', '3D25', '7KGQ', ...]

 #Example 6: Retrieve peptide template from database based on sequence
             similarity closest match.

     query_sequence="ALAKIMKAP"
     pdb_template=db.get_peptide_template()
     print(pdb_template)

     >6R2L
  '''
# ===============================================================================================
# To do:
# [X]    Add a step to self.build() that renumbers the receptor chain and peptide chain when building the database. There are a lot of messy PDBs that confuse Rosetta later in the pipeline. Fixed them manually for now, but this will help with most of them (they throw an "assertion "). The main problem is that the residues listed in database.info are not all present in the actual PDB.
#  [ ] Add additional functionality to remove_bad_pdbs that considers residues with single atoms at the N-terminus (a surprising number of failure cases are caused by this). Can try running simple Rosetta thread peptide implementation, or double checking that each residue has the expected number of atoms
# [ ] Add functionality to include MHC-I from other species (mouse, primarily)
# [ ] Add a cluster_templates method that assess template similarity by backbone structure rather than sequence similarity, and benchmark.
# [ ] Implement a "remote query" function, that can retrieve templates directly from the PDB rather than storing them locally.


# Import dependencies from standard python install
import os
import sys
from pathlib import Path
from zipfile import ZipFile
import subprocess
import shutil
import warnings

# From Biopython
from Bio import BiopythonWarning
from Bio import BiopythonDeprecationWarning
warnings.simplefilter('ignore',BiopythonWarning)
warnings.simplefilter('ignore',BiopythonDeprecationWarning)

from Bio import SeqIO
from Bio.PDB import PDBList
from Bio.PDB.PDBParser import PDBParser
from Bio.PDB import PDBIO
from Bio.PDB import StructureAlignment
from Bio.PDB.PDBIO import Select
from Bio.PDB import Atom
from Bio.PDB import Selection
from Bio import BiopythonParserWarning
from Bio import AlignIO
from Bio import pairwise2
from Bio.pairwise2 import format_alignment
from Bio.Align import substitution_matrices

# From other repositories
import requests
import pandas as pd

# Custom formatting class
from utilities import Notify

# Methods and classes called by class MHCdatabase:

def remove_bad_pdbs(templates_dir, struct_data):
    # A method to quickly error check all of our templates and get rid of bad ones. Based on the presumption that most errors are due to low peptide electron density and resultant missing residues in the PDB.
    bad_pdbs=[]
    fix_pdbs=[]
    bad_chain=[]
    bad_res=[]
    reported_seq=[]
    pdb_seq=[]
    pdbtot=len(struct_data)
    pdbnum=0
    for pdb in struct_data["PDB_ID"].tolist():
        pdbnum+=1
        print(f"Now error checking PDB {pdbnum:<5} of {pdbtot} in {templates_dir}...",end="\r")
        tmp_reported_seq=struct_data.loc[struct_data["PDB_ID"]==pdb,["Epitope_Description"]].iloc[0,0]
        epitope_chain_id=struct_data.loc[struct_data["PDB_ID"]==pdb,["Antigen_PDB_Chain(s)"]].iloc[0,0]
        tmp_record=SeqIO.parse(os.path.join(templates_dir,pdb)+".pdb","pdb-seqres")

        for record in SeqIO.parse(os.path.join(templates_dir,pdb)+".pdb","pdb-atom"):
            # print(record.id)
            if record.annotations["chain"]==epitope_chain_id:
                if tmp_reported_seq != str(record.seq):
                    bad_pdbs.append(pdb)
                    reported_seq.append(tmp_reported_seq)
                    pdb_seq.append(str(record.seq))

        # If the sequence is OK, now we iterate through the residues and make sure the expected number of heavy atoms are present in each residue
        tmp_struct=PDBParser(PERMISSIVE=1, QUIET=1).get_structure(pdb,os.path.join(templates_dir,pdb+".pdb"))[0]
        rescount=1
        for chain in tmp_struct.get_chains():
            for residue in chain.get_residues():
                atomcount=0
                for atom in residue.get_atoms():
                    atomcount+=1
        # If the number of atoms is unexpectedly low for a given residue, remove it from the template (a more or less arbitrary fix which takes care of edge cases where the residue at the N-terminus of the MHC-1 receptor has no atoms). Check only the terminus atoms
                if atomcount<3:
                    bad_chain.append(chain)
                    bad_res.append(rescount)
                    fix_pdbs.append(pdb)
                rescount+=1

    print()
    # Remove the bad terminal residues from PDBs identified earlier
    if len(fix_pdbs)>0:
        print("Removing bad residues from: {}".format(", ".join(fix_pdbs)))
        for pdb,chain,res in list(zip(fix_pdbs,bad_chain,bad_res)):
            tmp_fn=os.path.abspath(os.path.join(templates_dir,pdb+".pdb"))
            tmp_struct=PDBParser(PERMISSIVE=1, QUIET=1).get_structure(pdb,tmp_fn)[0]
            io=PDBIO()
            io.set_structure(tmp_struct)
            io.save(tmp_fn,residueSelect(chain,res))

    # Print information on PDBs that were culled because their epitope sequence did not match the database sequence
    if len(bad_pdbs)==0:
        print("Error checking complete.")
    else:
        print(f"Error checking complete. The following bad PDB files were located and removed from database ({len(bad_pdbs)} total):")
        struct_data.drop(struct_data[struct_data.PDB_ID.isin(bad_pdbs)].index,inplace=True)
        struct_data.reset_index(drop=True)
        print("{:<10}{:<25}{:<25}".format("PDB","IEDB sequence","PDB sequence"))
        for row in zip(bad_pdbs,reported_seq,pdb_seq):
            print("{:<10}{:<25}{:<25}".format(*row))


    return struct_data

class residueSelect(Select):
    # Subclass for overloading default selector class in Bio.PDB.PDBIO
    def __init__(self,rem_chain,rem_res):
        self.rem_chain=rem_chain
        self.rem_res=rem_res

    def accept_residue(self,residue):
        if residue.get_id()[1]==self.rem_res:
            return False
        else:
            return True

class chainSelect(Select):
    # Quick subclass to help us select chains from the PDBs (both MHC and peptide chains)
    # Overloads the default Select class in Bio.PDB.PDBIO
    def __init__(self,MHC,pep):
        self.MHC_chain=MHC
        self.pep_chain=pep

    def accept_chain(self,chain):
        if chain.get_id()==self.MHC_chain or chain.get_id()==self.pep_chain:
            return True
        else:
            return False

    # Omit HETATMs
    def accept_atom(self, atom):
        # In BioPDB terms, a space at the 3,0 position of get_full_id corresponds to a HETATM
        if atom.get_full_id()[3][0]==' ':
            return True
        else:
            return False

class MHCdatabase:
    __LOCATE__=os.path.join(os.environ["HOME"],"Data/MHC_database/")
    allele=None    # The allele that this instance of the datbase points to
    templates=[]   # A list of alleles similar in sequence to be used as structural templates, with sequences in order from most similar at index 0 to least at index -1
    sequence=""    # The sequence of self.allele, trimmed to alpha 1 and alpha 2 domains
    receptor=None  # PDB filename with the receptor to use in downstream modeling applications. Can be created by calling self.build_receptor()
    mute=False #
    def __init__(self, location=__LOCATE__, build=False, allele=None):
        # Class constructor. Can set database location when calling. Optionally set build to True to build database at specified location and set an allele.
        self.locate=location # Set database location and make sure it's valid

        if not Path(location).is_dir():
            notify().warn(f"{location} does not exist. Creating directory (and parents)...")
            Path(location).mkdir(parents=True,exist_ok=True)
            build=True

        if build:
            print(f"Now building MHC database at {location}")
            self.build()

        if allele: # Constructor will retrieve structural templates and attempt to build a receptor by default. To change this behavior, call MHCdatabase().set_allele(get_templates=False, build_receptor=False)
            self.set_allele(allele)

    def build(self, allele_list=None, update=False, mouse_only=False):
        # A call to build the database. If update=True passed, then it builds the database with newly downloaded data. Takes in a location of a list of HLA alleles with full sequences (allele_list) and an option to update the database with freshly downloaded sequence data or to use pre-existing sequence data (if database.info file already exists)
        # mouse_only: parameter that if set to true, will build database with H2-Db and H2-Kb epitopes.

        # Interpret the location. If it does not already exist, attempt to create it.
        if not Path(self.locate).is_dir():
            notify().warn(f"Database location does not exist. Creating directory {self.locate}...")
            Path(self.locate).mkdir(parents=True, exist_ok=True)

        # Create the /<MHCdatabase>/build folder to store files in for the database build
        build_dir=os.path.abspath(os.path.join(self.locate,"build"))
        if not Path(build_dir).is_dir():
            Path(build_dir).mkdir(parents=True, exist_ok=True)

        # Create directories /templates for PDB peptide templates and /default_receptor for AlphaFold2 MHC receptor models
        templates_dir=os.path.join(self.locate,"templates")
        defaultReceptor_dir=os.path.join(self.locate,"default_receptor")
        if not Path(templates_dir).is_dir():
            Path(templates_dir).mkdir(parents=True, exist_ok=True)
        if not Path(defaultReceptor_dir).is_dir():
            Path(defaultReceptor_dir).mkdir(parents=True, exist_ok=True)

        # Download allele list:
        fetch_allele_data=self.fetch_mhc_allele_info(allele_list=allele_list, update=update)
        allele_data=fetch_allele_data[0]
        allele_name_unique=allele_data.Allele_Name.unique()

        # Now we build the structural data for the database. Download the necessary data files from IEDB:
        IEDB_MHC_LIGAND_FULL="https://www.iedb.org/downloader.php?file_name=doc/mhc_ligand_full_single_file.zip"
        IEDB_STRUCT_DATA="https://www.iedb.org/downloader.php?file_name=doc/iedb_3d_full.zip"

        # Download the MHC structural database file if not in the build folder already:
        struct_data_tcr_fn=os.path.join(build_dir,"tcr_3d_assays.csv")
        struct_data_mhc_fn=os.path.join(build_dir, "mhc_3d_assays.csv")

        success=False
        if Path(struct_data_tcr_fn).is_file() and Path(struct_data_mhc_fn).is_file():
            success=True
            print(f"IEDB structure data files {struct_data_tcr_fn} and {struct_data_mhc_fn} located")
        else:
            print("Downloading IEDB data from https://www.iedb.org...")
            success=True
            try:
                struct_data=requests.get(IEDB_STRUCT_DATA)
                if struct_data.status_code != 200:
                    success=False
            except requests.exceptions.RequestException:
                success=False

            if not success:
                notify().error(f"{IEDB_STRUCT_DATA} or {IEDB_PDB_TO_EPITOPE_MAPS} are not reachable\nUnable to build database. Terminating execution")
                return success

            # Retrieve the data:
            struct_data_zip_fn=os.path.join(build_dir,os.path.basename(IEDB_STRUCT_DATA))
            struct_data_zip=requests.get(IEDB_STRUCT_DATA, stream=True)
            with open(struct_data_zip_fn, mode="wb") as sfile:
                for chunk in struct_data_zip.iter_content(chunk_size=1024):
                    if chunk:
                        sfile.write(chunk)
            print(f"Structure data retrieved and written to {struct_data_zip_fn}")
            with ZipFile(struct_data_zip_fn,"r") as zfile:
                zfile.extractall(path=build_dir)

            os.remove(struct_data_zip_fn)
            # Remove antibody/b-cell receptor epitope structure data
            if Path(os.path.join(build_dir,"bcr_3d_assays.csv")).is_file():
                os.remove(os.path.join(build_dir,"bcr_3d_assays.csv"))

        # Now read the data into pandas dataframes and filter out duplicate epitopes, keeping only the highest resolution structures of all the duplicates:

        struct_data_tcr=pd.read_csv(struct_data_tcr_fn,header=1)
        # Clean up the fieldnames
        struct_data_tcr.columns=struct_data_tcr.columns.str.replace(" ","_")
        struct_data_tcr.columns=struct_data_tcr.columns.str.replace("/","-")

        struct_data_mhc=pd.read_csv(struct_data_mhc_fn,header=1)
        # Clean up the fieldnames
        struct_data_mhc.columns=struct_data_mhc.columns.str.replace(" ","_")
        struct_data_mhc.columns=struct_data_mhc.columns.str.replace("/","-")

        # Concatenate structure data from TCRs and MHC only PDB files into a single dataframe for ease of use:
        struct_data_mhc.rename(columns={"MHC_PDB_Chain_1":"MHC_PDB_Chain1"},inplace=True)
        cols=["Epitope_IRI","Epitope_Description","MHC_Allele","MHC_PDB_Chain1","Antigen_PDB_Chain(s)","PDB_ID","Resolution_(Angstrom)"]

        struct_data=pd.concat([struct_data_tcr[cols],struct_data_mhc[cols]],axis=0,ignore_index=True,)

        # Generate column with epitope IDs
        struct_data["Epitope_ID"]=struct_data["Epitope_IRI"].str.split("/").apply(lambda x:x[-1])
        struct_data.drop(columns=["Epitope_IRI"])

        # Save structures with mouse alleles H2-Db and H2-Kb
        mouse_struct_data=struct_data.loc[(struct_data["MHC_Allele"]=="H2-Db") | (struct_data["MHC_Allele"]=="H2-Kb")]

        # Remove structures without a corresponding class 1 HLA allele in the pre-generated list of HLA alleles (i.e., CD1, MHC class 2, etc)
        struct_data=struct_data[struct_data["MHC_Allele"].isin(["{}{}".format("HLA-",i) for i in allele_name_unique])]
        struct_data["MHC_Allele"]=struct_data["MHC_Allele"].str.split("-").apply(lambda x:x[-1])

        # Recombine mouse and human data
        struct_data=pd.concat([struct_data,mouse_struct_data],ignore_index=True)

        stats_total=len(struct_data)

        # Remove structures with duplicate epitopes and NCAA that might not be recognized by Rosetta when threading for flexpepdock
        stats_with_NCAA=len(struct_data[struct_data["Epitope_Description"].str.contains("\+")])
        struct_data=struct_data[~struct_data["Epitope_Description"].str.contains("\+")]

        allele_list_struct=struct_data["MHC_Allele"].unique().tolist()

        # Remove structures with duplicate epitopes, keeping only the highest resolution structure
        stats_duplicates=0
        for a in allele_list_struct:
            tmp_epitopes_list=struct_data["Epitope_ID"].loc[struct_data["MHC_Allele"]==a].unique().tolist()
            for e in tmp_epitopes_list:
                e_struct=struct_data.loc[(struct_data["MHC_Allele"]==a) & (struct_data["Epitope_ID"]==e)]
                if len(e_struct)>1:
                    stats_duplicates+=len(e_struct.index[e_struct["Resolution_(Angstrom)"]>e_struct["Resolution_(Angstrom)"].min()].tolist())
                    struct_data.drop(e_struct.index[e_struct["Resolution_(Angstrom)"]>e_struct["Resolution_(Angstrom)"].min()].tolist(),inplace=True)

        struct_data.reset_index(inplace=True,drop=True)

        # Print query statistics
        title1="MHC-I structures total"
        title2="Structures with NCAA"
        title3="Structures duplicate epitopes"
        title4="Total MHC-I structures with unique epitopes"
        title5="Unique alleles with PDB structures"
        print(f"{title1:<45} : {stats_total}")
        print(f"{title2:<45} : {stats_with_NCAA}")
        print(f"{title3:<45} : {stats_duplicates}")
        print(f"{title4:<45} : {len(struct_data)}")
        print(f"{title5:<45} : {len(allele_list_struct)}")

        # Iterate through all HLAs in the database. For each allele, search the structure data - if the allele exists, download it from the PDB to <allele_name>. Keep only the MHC and peptide chains.

        # This is for updating the database only. Check if the info file is found.
        dbinfo_fn=os.path.join(self.locate,"database.info")
        if Path(dbinfo_fn).is_file():
            database_info=pd.read_csv(dbinfo_fn)
            print(f"{dbinfo_fn} located. Updating database with new structures...")
        else:
            database_info=pd.DataFrame(columns=struct_data.columns)
            print(f"{dbinfo_fn} not found. Building database from the ground up...")

        title1="Allele"
        title2="#PDBs"
        title3="Now Downloading..."
        print(f"\n{title1:^15}|{title2:^5}|{title3:^15}\n===============|=====|===============")
        download_count=0

        for a in allele_name_unique:
            if a in allele_list_struct:
                # If an allele has at least one structure in the PDB, retrieve them
                tmp_pdb=struct_data["PDB_ID"].loc[(struct_data["MHC_Allele"]==a)].tolist()
                for (i,p) in enumerate(tmp_pdb):
                    # Download each PDB file that does not already exist in the database
                    print(f"{a:^15}|{i+1:^5}|{p:^15}| Downloaded:{download_count:<5}Remaining:{len(struct_data)-download_count:<5}", end="\r")
                    if p.upper() not in database_info["PDB_ID"].tolist():
                        tmp_fn=PDBList(verbose=False).retrieve_pdb_file(pdb_code=p,file_format="pdb",pdir=templates_dir)
                        # Clean the PDB file: remove HETATMs, keep only alpha chain of MHC and peptide
                        tmp_struct=PDBParser(PERMISSIVE=1, QUIET=1).get_structure(p,tmp_fn)[0]
                        chain_MHC=struct_data["MHC_PDB_Chain1"].loc[(struct_data["PDB_ID"]==p)].tolist()[0]
                        chain_peptide=struct_data["Antigen_PDB_Chain(s)"].loc[(struct_data["PDB_ID"]==p)].tolist()[0]
                        io=PDBIO()
                        io.set_structure(tmp_struct)
                        tmp_remove=tmp_fn
                        tmp_fn=os.path.join(os.path.dirname(tmp_fn),os.path.basename(tmp_fn)[-8:-4].upper()+".pdb")
                        # Save the file with the custom overloaded class that will select only for the MHC and peptide chains, and remove HETATMs
                        io.save(tmp_fn,chainSelect(chain_MHC,chain_peptide))
                        os.remove(tmp_remove) # Remove the downloaded file
                    download_count+=1
                print(f"{a:^15}|{i+1:^5}|{p:^15}|                                ")

        print(f"Database built at {self.locate}. Error checking PDB files...")

        # Next we error check the PDBs for bad files, usually where the peptide sequence of the PDB file does not match that of the template.
        struct_data=remove_bad_pdbs(templates_dir,struct_data)

        # Now save our database.info file for future reference
        struct_data.to_csv(os.path.join(self.locate,"database.info"),index=False)

        print(f"Database info saved to {os.path.join(self.locate,'database.info')}")

        # Print statistics about the database for user reference
        self.query_mhc_database()

        return

    def query_mhc_database(self, allele="all", quiet=False, getpdb=False, getepitopes=False, gettemplate=False):
        # Utility to query information about structures in MHC/peptide database by accessing and returning requested data from database.info
        # Each behavior output is formatted as a tuple, with the second value a boolean indicating success or failure of the requested operation.
        # Description of method behavior based on options set by user in execution priority order (will only do one of these things at a time):
        #  allele="all": Prints a formatted table and returns a list of all available alleles if allele="all" (default behavior).
        #             Returns a True value if the value for MHCdatabase().allele is present in database.info
        #  allele="<some HLA here>": Returns a boolean value indicating whether or not requested allele is present (True) or absent (False)
        #  getpdb=True: Prints and returns a list of PDBs with templates for MHCdatabase().allele.   If no allele value set for database instance, will return all PDBs belonging to the variable allele. If that variable is set to the default ("all"), then will return all PDBs in database. If no PDBs are found, also returns false
        #  getepitopes: Returns a dictionary where each key corresponds to a PDB ID in the database, and the value is the epitope sequence.
        #  gettemplate: Assign a 4-letter string corresponding to a PDB ID. Returns a dictionary where each key corresponds to database.info column values for a given PDB in the database, and a boolean indicating whether or not the PDB was found.
        # Extra variable to define behavior for each requested operation:
        #  quiet=True: Supress the printing of structure info to screen by setting quiet=True

        dbinfo=os.path.join(self.locate,"database.info")

        # Quick check to make sure the database.info file exists
        if not Path(dbinfo).is_file():
            notify().error(f"{dbinfo} not located. Does it exist?")
            allele_list=[]
            allele_present=False
            return allele_list, allele_present

        # If it exists, get the database information contained within
        db_data=pd.read_csv(dbinfo)

        # Return a list of PDBs for a given allele if requested ("getpdb=True"). By default, returns PDBs for the allele set in the database instance. This behavior can be overwritten if MHCdatabase().allele=None and allele=<some value> is passed to query_mhc_database
        if getpdb:
            if allele=="all" and self.allele==None:
                pdbs=db_data
            elif self.allele==None:
                notify().warn(f"No allele value set for database instance. Retrieving PDBs for {allele}")
                pdbs=db_data.loc[db_data["MHC_Allele"]==allele].copy()
            else:
                allele=self.allele
                pdbs=db_data.loc[db_data["MHC_Allele"]==allele].copy()

            pdbs.sort_values(by="Resolution_(Angstrom)",ignore_index=True,inplace=True,ascending=True)
            pdb_ids=pdbs["PDB_ID"].tolist()

            if not quiet:
                if len(pdb_ids)==0:
                    print(f"No PDBs found in database for {allele}")
                else:
                    print("{:^15}{:^20}{:^10}{:^20}".format(allele+" PDBs","Epitope","Length","Resolution (A)"))
                    for pdb in pdb_ids:
                        tmp_epitope=pdbs['Epitope_Description'].loc[pdbs['PDB_ID']==pdb].values[0]
                        tmp_length=len(tmp_epitope)
                        tmp_res=pdbs['Resolution_(Angstrom)'].loc[pdbs['PDB_ID']==pdb].values[0]
                        print(f"{pdb:^15}|{tmp_epitope:<20}|{tmp_length:^10}|{tmp_res:^20}")

            if len(pdb_ids)==0:
                pdb_found=False
            else:
                pdb_found=True

            return pdb_ids, pdb_found

        # Return a dictionary with key:value pairs corresponding to PDB:epitope sequences for the requested allele. If database instance has no allele set and allele="all" in the call to query_mhc_database(), will return a dict with all PDB and all epitope sequences.
        if getepitopes:
            if allele=="all" and self.allele==None:
                pdbs=db_data
                epitopes=db_data["Epitope_Description"].tolist()
                pdb_ids=db_data["PDB_ID"].tolist()
            elif self.allele==None:
                if not quiet:
                    notify().warn(f"No allele value set for database instance. Retrieving epitope sequences for {allele}")
                pdbs=db_data.loc[db_data["MHC_Allele"]==allele].copy()
                epitopes=db_data["Epitope_Description"].loc[db_data["MHC_Allele"]==allele].tolist()
                pdb_ids=db_data["PDB_ID"].loc[db_data["MHC_Allele"]==allele].tolist()
            else:
                allele=self.allele
                pdbs=db_data.loc[db_data["MHC_Allele"]==allele].copy()
                epitopes=db_data["Epitope_Description"].loc[db_data["MHC_Allele"]==allele].tolist()
                pdb_ids=db_data["PDB_ID"].loc[db_data["MHC_Allele"]==allele].tolist()

            if not quiet:
                if len(pdb_ids)==0:
                    print(f"No epitope sequences found in database for {allele}")
                else:
                    print("{:^15}{:^20}{:^10}".format(allele+" PDBs","Epitope","Length"))
                    for pdb in pdb_ids:
                        tmp_epitope=pdbs['Epitope_Description'].loc[pdbs['PDB_ID']==pdb].values[0]
                        tmp_length=len(tmp_epitope)
                        print(f"{pdb:^15}|{tmp_epitope:^20}|{tmp_length:^10}")

            if len(pdb_ids)==0:
                epitopes_found=False
            else:
                epitopes_found=True

            return dict(zip(pdb_ids,epitopes)), epitopes_found

        if gettemplate:
            if gettemplate in db_data["PDB_ID"].tolist():
                return dict(zip(db_data.columns.tolist(),db_data.loc[db_data["PDB_ID"]==gettemplate].values.tolist()[0])), True
            else:
                notify().warn(f"Requested template {gettemplate} does not exist in database!")
                if not quiet:
                    print("Available templates include:")
                    db_data.sort_values(by=["MHC_Allele"],inplace=True,ignore_index=True)
                    pdb_ids=db_data["PDB_ID"].tolist()
                    print("{:^10}|{:^10}".format("Allele","PDB"))
                    print("---------------------")
                    for pdb in pdb_ids:
                        print(f"{db_data['MHC_Allele'].loc[db_data['PDB_ID']==pdb].values[0]:^10} {pdb}")
                return dict(zip(db_data.columns.tolist(), [None]*len(db_data.columns.tolist()))), False

        allele_list=db_data["MHC_Allele"].sort_values().unique().tolist()
        # If user requests all data, return the allele list
        if allele=="all":
            if not quiet:
                print()
                print("{:^50}".format("==== MHC-1 Database @"+self.locate+"====\n"))
                # Print basic statistics about the database:
                A_alleles=sum("A" in s for s in allele_list)
                A_count=sum(db_data["MHC_Allele"].str.contains("A").tolist())
                B_alleles=sum("B" in s for s in allele_list)
                B_count=sum(db_data["MHC_Allele"].str.contains("B").tolist())
                C_alleles=sum("C" in s for s in allele_list)
                C_count=sum(db_data["MHC_Allele"].str.contains("C").tolist())
                print("{:^50}".format("-----------Summary Statistics-----------\n"))
                total_alleles=len(allele_list)
                total_PDBs=len(db_data)
                print("{:<10}{:^20}{:^25}".format("Gene","Unique Alleles","Structures with Unique Epitopes"))
                print("{:<10}{:^20}{:^25}".format("All",total_alleles,total_PDBs))
                print("{:<10}{:^20}{:^25}".format("HLA-A",A_alleles,A_count))
                print("{:<10}{:^20}{:^25}".format("HLA-B",B_alleles,B_count))
                print("{:<10}{:^20}{:^25}\n".format("HLA-C",C_alleles,C_count))
                title_allele="Allele"
                title_numstruct="Number of PDBs"
                print("{:^50}".format("----------All Available Alleles----------\n"))
                print("{:^10}{:^20}".format("Allele","# of Structures"))
                for a in allele_list:
                    num_pdbs=len(db_data["PDB_ID"].loc[(db_data["MHC_Allele"]==a)])
                    print(f"{a:^10}{num_pdbs:^15}")

            if self.allele in allele_list:
                allele_present=True
            else:
                allele_present=False

            return allele_list, allele_present

        # Find requested allele (if not set to "all") and return a list of all alleles in the database
        if allele!="all" and allele in allele_list:
            allele_present=True
        else:
            allele_present=False

        return allele_list, allele_present

    def set_allele(self, check_allele, get_templates=True, build_receptor=True):
        # Check if allele is available. Sets the class variable equal to the requested allele.
        # Also returns a bool corresponding to allele availability.
        # If the allele does not have any structure templates, then find the closest allele match by sequence that does
        # This method will automatically set self.templates and self.sequence as well.
        alist, apresent = self.query_mhc_database(allele=check_allele)
        self.allele=check_allele

        # Retrieved the alpha 1/alpha 2 domain sequences and find the one for this allele
        allele_sequences=self.fetch_mhc_allele_info()
        allele_sequences=allele_sequences[1]
        if not allele_sequences["Allele_Names"].str.contains(self.allele,regex=False).any():
            # Check if the sequence exists
            notify().error(f"Failed to set allele to {self.allele}; the requested allele has no available sequence!\nMake sure allele is formatted <gene>*<allele_number>:<protein>. Example: A*02:01")
            self.allele=None
            return False
        else:
            # Find the sequence (already trimmed)
            self.sequence=allele_sequences["Sequence"].loc[allele_sequences["Allele_Names"].str.contains(self.allele,regex=False)].values[0]

        db_print(f"Allele set to:\n{self.allele}",mute=self.mute)
        db_print(f"{self.allele} alpha 1 and alpha 2 domain amino acid sequence retrieved:\n{self.sequence}",mute=self.mute)

        # Check if the allele is present in the structure database (a formality to notify the user)
        if not apresent and not self.mute:
            notify().warn(f"{check_allele} is not present in structure database!")

        if get_templates:
            self.templates=self.set_mhc_templates()
            if self.templates:
                db_print("Structural templates identified in sequence identity order:\n{}".format(", ".join(self.templates)),mute=self.mute)

        if build_receptor:
            self.build_receptor()

        return True

    def fetch_mhc_allele_info(self, allele_list=None, update=False):
        # A utility to download and return the contents of all available HLA allele protein sequences in a single file
        # Download allele list to file, pulling from IMGT database if no url or file provided
        # Optional argument "update" if set to default will return data in allele_seq.info without downloading and processing the allele list from the IMGT database. Set update=True to download new data and overwrite existing allele_seq.info file.
        default_alleleList= "https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/hla_prot.fasta"
        allele_list_fn=os.path.join(self.locate,"build","allele_list.fasta")

        # Check if the default allele list exists and return requested values without update (or proceed with update)
        seq_data_default_fn=os.path.abspath(os.path.join(self.locate,"build","allele_seq.info"))
        allele_data_default_fn=os.path.abspath(os.path.join(self.locate,'build','allele_list.info'))
        if Path(allele_data_default_fn).is_file() and Path(seq_data_default_fn).is_file():
            allele_data=pd.read_csv(allele_data_default_fn)
            seq_data=pd.read_csv(seq_data_default_fn)
            if not update:
                return allele_data, seq_data
            else:
                print(f"File {allele_data_default_fn} and {seq_data_default_fn} located. Overwriting existing files with new data.")

        # Check if the allele list was omitted or if the file provided is invalid
        if allele_list and Path(allele_list).is_file():
            print(f"File {allele_list} located")
            allele_list_fn=os.path.abspath(allele_list)
        elif Path(allele_list_fn).is_file():
            print(f"File {allele_list_fn} located")

        # If the file does not exist, check and see if it is a valid URL. If so, download the allele data - if not, then use the default download location (IMGT database)
        else:
            try:
                get=requests.get(allele_list)
                if get.status_code != 200:
                    allele_list=default_alleleList
                    notify().warn(f"{allele_list} is not reachable")
            except requests.exceptions.RequestException:
                if not allele_list:
                    notify().warn(f"No allele list file or URL specified. Attempting download from {default_alleleList}")
                else:
                    notify().warn(f"{allele_list} is unreachable. Downloading allele data from {default_alleleList}")
                allele_list=default_alleleList

            # A quick check to make sure the default URL is reachable if it is needed
            success=True
            try:
                get=requests.get(allele_list)
                if get.status_code != 200:
                    success=False
            except requests.exceptions.RequestException:
                success=False
            if not success:
                notify().error(f"Unable to reach default allele list location at\n{default_alleleList}\nTerminating execution")
                return success
            # Otherwise proceed with the download
            tmp_data=requests.get(allele_list, stream=True)
            with open(allele_list_fn, "wb") as afile:
                for chunk in tmp_data.iter_content(chunk_size=1024):
                    if chunk:
                        afile.write(chunk)
            print(f"Allele fasta downloaded to {allele_list_fn}")

        # Now load the data into a pandas dataframe. Limit to A, B, and C genes
        print("Now processing allele sequence list...",end="")
        print("removing non-class-I MHCs...",end="")
        with open(allele_list_fn) as allele_fasta:
            allele_name=[]
            allele_seq=[]
            epitope_present=[]
            count_absent=0
            for record in SeqIO.parse(allele_fasta, "fasta"):
                tmp_des=record.description.split(" ")[1]
                tmp_gene=tmp_des.split("*")[0]
                if (tmp_gene=="A" or tmp_gene=="B" or tmp_gene=="C"):
                    allele_name.append(tmp_des)
                    allele_seq.append(str(record.seq))
        allele_data=pd.DataFrame(columns=["Allele","Sequence"])
        allele_data["Allele"]=allele_name
        allele_data["Sequence"]=allele_seq

        # Remove sequence duplicates
        print("removing duplicate MHCs...",end="")
        allele_data.drop_duplicates(subset="Sequence",inplace=True,ignore_index=True)

        # Remove alleles with N (null), S (secreted), C (cytoplasmic), A (aberrant), and Q (questionable) suffixes
        print("removing alleles with N (null), S (secreted), C (cytoplasmic), A (aberrant), and Q (questionable) suffixes...",end="")
        discard_filter="NSCAQ"
        allele_data["tmp_alleleName"]=allele_data["Allele"].str.split("*").apply(lambda x:x[1])
        allele_data=allele_data[~allele_data.tmp_alleleName.str.contains("|".join(discard_filter))]
        allele_data.drop(columns=["tmp_alleleName"])
        allele_data.reset_index(inplace=True,drop=True)

        # We want only specific proteins. Create a new column that describes the specific HLA protein (i.e., A*02:01). For all synonymous DNA substitution variants, select the longest sequence length. We will save the sequence data for building "default receptors" to be used in future peptide binding simulations.
        print("removing synonymous DNA substitution variants...")
        allele_data["Allele_Name"]=allele_data["Allele"].str.split(":").apply(lambda x:x[0:2]).apply(lambda x:":".join(x))
        allele_data["tmp_seqLen"]=allele_data["Sequence"].apply(lambda x:abs(len(x)-181))
        allele_name_unique=allele_data.Allele_Name.unique().tolist()

        for a in allele_name_unique:
            tmp=allele_data.loc[(allele_data["Allele_Name"]==a)].copy()
            if len(tmp)>1: # If a given allele has synonymous variants,
                # keep only the variant with the sequence closest in length to 181 (length of alpha1 and alpha2 domains)
                allele_data.drop(tmp.index[tmp["tmp_seqLen"]>tmp["tmp_seqLen"].min()].tolist(),inplace=True)

        allele_data.drop(columns=["tmp_alleleName","tmp_seqLen","Allele"],inplace=True) # Discard unused columns

        # Define full sequences for H2-Kb and H2-Db for inclusion of mouse data
        H2Db_seq="MGAMAPRTLLLLLAAALAPTQTRAGPHSMRYFETAVSRPGLEEPRYISVGYVDNKEFVRFDSDAENPRYEPRAPWMEQEGPEYWERETQKAKGQEQWFRVSLRNLLGYYNQSAGGSHTLQQMSGCDLGSDWRLLRGYLQFAYEGRDYIALNEDLKTWTAADMAAQITRRKWEQSGAAEHYKAYLEGECVEWLHRYLKNGNATLLRTDSPKAHVTHHPRSKGEVTLRCWALGFYPADITLTWQLNGEELTQDMELVETRPAGDGTFQKWASVVVPLGKEQNYTCRVYHEGLPEPLTLRWEPPPSTDSYMVIVAVLGVLGAMAIIGAVVAFVMKRRRNTGGKGGDYALAPGSQSSEMSLRDCKA"
        H2Kb_seq="MVPCTLLLLLAAALAPTQTRAGPHSLRYFVTAVSRPGLGEPRYMEVGYVDDTEFVRFDSDAENPRYEPRARWMEQEGPEYWERETQKAKGNEQSFRVDLRTLLGYYNQSKGGSHTIQVISGCEVGSDGRLLRGYQQYAYDGCDYIALNEDLKTWTAADMAALITKHKWEQAGEAERLRAYLEGTCVEWLRRYLKNGNATLLRTDSPKAHVTHHSRPEDKVTLRCWALGFYPADITLTWQLNGEELIQDMELVETRPAGDGTFQKWASVVVPLGKEQYYTCHVYHQGLPEPLTLRWEPPPSTVSNMATVAVLVVLGAAIVTGAVVAFVMKMRRRNTGGKGGDYALAPGSQTSDLSLPDCKVMVHDPHSLA"
        # Include mouse data here
        mouse_data=pd.DataFrame(data={"Sequence":[H2Db_seq,H2Kb_seq],"Allele_Name":["H2-Db","H2-Kb"]})
        allele_data=pd.concat([allele_data,mouse_data],ignore_index=True)

        allele_data.reset_index(inplace=True,drop=True)
        allele_data.reindex(columns=allele_data.columns.tolist()+["Templates"],copy=False)
        allele_data.to_csv(allele_data_default_fn,index=False)
        print(f"Allele list and corresponding sequences generated and saved to {allele_data_default_fn}. {len(allele_data)} sequenced alleles retrieved")

        # Here we build a compressed file with non-redudant sequences of the alpha 1 and alpha 2 domains. The "Allele_Names" column will be a list of alleles that have these sequences.
        seq_trim=[]
        print(f"Trimming sequences and saving only non-redundant values...")
        for a in allele_data["Allele_Name"].tolist():
            if a not in ["H2-Db","H2-Kb"]:
                tmpseq=self.trim_seq(allele_data["Sequence"].loc[allele_data["Allele_Name"]==a].values[0],a[0])
                seq_trim.append(tmpseq)
            else:
                tmpseq=self.trim_seq(allele_data["Sequence"].loc[allele_data["Allele_Name"]==a].values[0],a)
                seq_trim.append(tmpseq)
            if len(seq_trim)%10==0 or len(seq_trim)==len(allele_data):
                print(f"Trimmed {len(seq_trim):<5} of {len(allele_data)} sequences",end="\r")

        print()
        allele_data["Sequence_trimmed"]=seq_trim
        seq_trim=allele_data.Sequence_trimmed.unique().tolist()
        seq_trim=pd.DataFrame(seq_trim,columns=["Sequence"]) # Save unique sequences to a new dataframe, and then find their matching HLAs

        hla_list=[]
        for s in seq_trim["Sequence"].tolist():
            tmp=allele_data["Allele_Name"].loc[allele_data["Sequence_trimmed"]==s].values
            tmp_hla_list=""
            for v in tmp:
                if tmp_hla_list=="":
                    tmp_hla_list=v
                else:
                    tmp_hla_list=tmp_hla_list+" "+v
            hla_list.append(tmp_hla_list)
        seq_trim["Allele_Names"]=hla_list

        seq_trim.to_csv(os.path.join(self.locate,"build","allele_seq.info"),index=False)
        print(f"Non-redundant alpha1 and alpha2 domain sequences saved to {os.path.join(self.locate,'build','allele_seq.info')}")

        return allele_data, seq_trim

    def set_mhc_templates(self):
        # If an allele has no structure in the database onto which a peptide can be threaded, then we need to find one. For the allele in question, generate a list of closest matching alleles by protein sequence with available structure templates. Attempt to align alpha1 and alpha2 domains ONLY. Then sort by alignment score, and return the list alleles in the structure database ordered by highest->lowest score.
        # regen: optional parameter that forces re-generation of new templates each time this method is called. Alternatively, if templates have been generated to the past and saved as a list to allele_seq.info, then they will be read and returned with the next call (to save time)

        # Make sure an allele is set to match
        toMatch=self.allele
        if not self.allele:
            notify().error("No allele set. Call MHCdatabase().set_allele(<allele-name>) before identifying match")
            return None

        # Add a line to handle mouse alleles
        if toMatch in ["H2-Kb","H2-Db"]:
            notify().warn(f"No similar alleles to mouse allele {toMatch}")
            return None

        # Retrieve the sequence of the allele we want to find templates for (set it and trim it with self.set_allele() if not done already)
        if self.sequence=="":
            notify().warn(f"No sequence found for {self.allele}. Attempting to match with alpha 1/alpha 2 domain sequence in database...")
            chk=self.set_allele(self.allele,get_templates=False,build_receptor=False)
            if not chk: # Check to make sure sequence retrieval was successful
                return None

        toMatch_seq=self.sequence

        # Make sure that the database.info file exists
        dbinfo=os.path.join(self.locate,"database.info")
        if not Path(dbinfo).is_file():
            notify().error(f"{dbinfo} not found. Does it exist? If not, call MHCdatabase.build()")
            return None

        # Check and make sure the allele does not already have associated templates
        allele_data_info_fn=os.path.join(self.locate,"build","allele_list.info")
        if Path(allele_data_info_fn).is_file():
            allele_data_info=pd.read_csv(allele_data_info_fn)
            if "Templates" in allele_data_info.columns.tolist():
                hla_templates=allele_data_info["Templates"].loc[allele_data_info["Allele_Name"]==self.allele].values[0]
                if not pd.isna(hla_templates):
                    db_print(f"Ranked templates generated previously for {self.allele}",mute=self.mute)
                    return hla_templates.split(" ")
            else:
                allele_data_info.reindex(columns=allele_data_info.columns.tolist()+["Templates"],copy=False)
        else:
            notify().error(f"{allele_data_info_fn} not located. Does it exist? If not, try deleting {os.path.dirname(allele_data_info_fn)}/allele_seq.info and running the MHCdatabase().fetch_mhc_allele_info() method")
            return None

        db_print(f"No ranked templates identified for {self.allele}",mute=self.mute)

        # Read database info into pandas dataframe
        allele_data=self.fetch_mhc_allele_info()
        allele_data=allele_data[1]

        struct_data=pd.read_csv(dbinfo)
        allele_list_struct=struct_data["MHC_Allele"].unique().tolist()

        # Create a ranked list of structures based on sequence similarity. Do a pairwise alignment for each allele with a structure, and rank those alignments by score.
        tmp_alignments=pd.DataFrame(columns=["Aligned_to","score"])
        ranked_allele_matches=[]

        matrix = substitution_matrices.load("BLOSUM62")
        a_type=toMatch[0]

        for a2 in allele_list_struct: # ...Compare it to every allele with at least 1 available structure and score the alignment
            if a_type in a2:
                print(f"Generating ranked alignments for: {toMatch:<10} vs {a2:<10}",end="\r")

                # Obtain the trimmed alpha 1/alpha 2 domain sequence for the allele in the structure database
                a2_seq=allele_data["Sequence"].loc[allele_data["Allele_Names"].str.contains(a2,regex=False)].values[0]

                # Now do a global pairwise alignment and extract the best scoring result
                tmp_ava2=pairwise2.align.globalds(toMatch_seq,a2_seq, matrix, -10, -10) #Heavily penalize indels
                ava2_best=tmp_ava2[0]
                a_scores_best=ava2_best.score
                if len(tmp_ava2)>1:
                    for each_alignment in tmp_ava2:
                        if each_alignment.score<a_scores_best:
                            ava2_best=each_alignment
                            a_scores_best=ava2_best.score
                # Now concatenate the allele and its score to the dataframe
                tmp_alignments=pd.concat([tmp_alignments,pd.DataFrame(data={"Aligned_to":[a2],"score":[a_scores_best]},columns=["Aligned_to","score"])],ignore_index=True)
        print()
        tmp_alignments.sort_values(by="score",ascending=False,inplace=True) # Sort templates by alignment score, with the highest score at index=0

        # Write the data to allele_list.info in the /build folder so we don't have to do this again. Should speed up runtime for future applications, and with this approach we don't have to build templates for 13,000 HLAs (which would take...about 4.5 days of runtime, and then would have to be repeated if the database got updated...)
        allele_data_info.at[allele_data_info.loc[allele_data_info["Allele_Name"]==self.allele].index[0],"Templates"]=" ".join(tmp_alignments["Aligned_to"].tolist())
        allele_data_info.to_csv(allele_data_info_fn,index=False) # re-write the data file if updated

        return tmp_alignments["Aligned_to"].tolist()

    def trim_seq(self,seq,HLA_allele):
        # Method that takes in an HLA sequence and returns the alpha 1 and alpha 2 domains only, based on a simple sliding window alignment of the canonical domain sequences for each allele and the allele in question

        canon_domains={"A":"GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDQETRNVKAQSQTDRVDLGTLRGYYNQSEAGSHTIQIMYGCDVGSDGRFLRGYRQDAYDGKDYIALNEDLRSWTAADMAAQITKRKWEAAHEAEQLRAYLDGTCVEWLRRYLENGKETLQRT","B":"GSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPREEPRAPWIEQEGPEYWDRNTQIYKAQAQTDRESLRNLRGYYNQSEAGSHTLQSMYGCDVGPDGRLLRGHDQYAYDGKDYIALNEDLRSWTAADTAAQITQRKWEAAREAEQRRAYLEGECVEWLRRYLENGKDKLERA","C":"CSHSMRYFDTAVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPRGEPRAPWVEQEGPEYWDRETQKYKRQAQADRVSLRNLRGYYNQSEDGSHTLQRMSGCDLGPDGRLLRGYDQSAYDGKDYIALNEDLRSWTAADTAAQITQRKLEAARAAEQLRAYLEGTCVEWLRRYLENGKETLQRA","H2-Db":"GPHSMRYFETAVSRPGLEEPRYISVGYVDNKEFVRFDSDAENPRYEPRAPWMEQEGPEYWERETQKAKGQEQWFRVSLRNLLGYYNQSAGGSHTLQQMSGCDLGSDWRLLRGYLQFAYEGRDYIALNEDLKTWTAADMAAQITRRKWEQSGAAEHYKAYLEGECVEWLHRYLKNGNATLLRT","H2-Kb":"GPHSLRYFVTAVSRPGLGEPRYMEVGYVDDTEFVRFDSDAENPRYEPRARWMEQEGPEYWERETQKAKGNEQSFRVDLRTLLGYYNQSKGGSHTIQVISGCEVGSDGRLLRGYQQYAYDGCDYIALNEDLKTWTAADMAALITKHKWEQAGEAERLRAYLEGTCVEWLRRYLKNGNATLLRT"}
        canon_domain=canon_domains[HLA_allele]

        # Return hardcoded mouse alpha 1 and alpha 2 domains
        if HLA_allele in ["H2-Kb","H2-Db"]:
            return canon_domain[HLA_allele]

        # For now we will assume that if the sequence passed is less than the length of the canonical sequence, it contains both alpha 1 and alpha 2 domains (this appears to be true based on a review of the curated AA sequences)
        len_diff=len(seq)-len(canon_domain)
        if len_diff<=0:
            return seq

        # Otherwise do a simple sliding window of the canonical alpha1/alpha2 sequence vs the allele in question:
        # First create two lists of the same length with no overlapping characters:

        canon_domain_win=list(canon_domain)+[0]*(len(seq))
        seq_win=[0]*len(canon_domain)+list(seq)
        scores=[]
        alignments=[]
        # Now iterate the canonical sequence window over the entire length of the sequence in question, scoring at each position. The maximum score should correspond to the best possible alignment of the sequence with the canonical alpha 1/alpha 2 domains
        for ioffset in range(len(canon_domain_win)):
            tmpscore=0
            for (i,aa) in enumerate(seq_win):
                if aa!=0 and aa==canon_domain_win[i]:
                    tmpscore+=1
            scores.append(tmpscore)
            alignments.append([canon_domain_win,seq_win])
            canon_domain_win.pop()
            canon_domain_win=[0]+canon_domain_win

        # Now trim the sequence of the best alignment to fit the length of the canonical domains
        best_alignment=alignments[scores.index(max(scores))]
        newseq=""
        for i in range(len(best_alignment[0])):
            if best_alignment[0][i]!=0 and best_alignment[1][i]!=0:
                newseq=newseq+best_alignment[1][i]

        return newseq

    def build_receptor(self, overwrite=False, AF2_MINICONDA="/sb/apps/alphafold211/miniconda3", AF2_DATADIR="/sb/apps/alphafold-data", AF2_REPO="/sb/apps/alphafold211/alphafold"):
        # A method to build a homology model of the receptor in question.
        # Default behavior will be to call a local installation of alphafold at /sb/apps/alphafold211 with associated miniconda3 environment located
        # at /sb/apps/aphafold211/miniconda3. These variables can be adjusted as the user sees fit to implement on a local installation.
        # May optionally pass overwrite=True to overwrite a pre-existing receptor in the default_receptors directory of the database
        # Returns True if successful, False if not

        # Make sure the allele and sequence are set on the instance of the database class
        if not self.allele:
            notify().error("MHCdatabase().build_receptor() called but no allele set. Call HMCdatabase().set_allele() to set allele.")
            return False
        elif self.sequence=="":
            notify().warn(f"Allele set to {self.allele}, but no sequence found. Matching sequence now...")
            allele_test=self.set_allele(self.allele,get_templates=False,build_receptor=False)
            if not allele_test:
                return False

        # Make sure the necessary files and directories exist:
        receptor_dir=os.path.join(self.locate,"default_receptor")
        if not Path(receptor_dir).is_dir():
            notify().warn(f"Template directory not found. Creating template directory at {receptor_dir}")
            Path(receptor_dir).mkdir(parents=True,exist_ok=True)

        # Make sure the allele does not already have a sequence-matched structure
        seq_data=self.fetch_mhc_allele_info()
        seq_data=seq_data[1]
        seq_matches=seq_data["Allele_Names"].loc[seq_data["Sequence"]==self.sequence].values[0].split(" ")
        for a in seq_matches:
            if a!= self.allele:
                tmp_fn=os.path.join(receptor_dir,a+".pdb")
                if Path(tmp_fn).is_file():
                #notify().warn(f"File {tmp_fn} located. {a} is an exact alpha 1/alpha 2 domain sequence match with {self.allele}.\nSetting receptor to {tmp_fn}")
                    self.receptor=tmp_fn
                    return True

        # Check if file name exists - if overwrite was not passed, then the program will terminate in favor of the pre-existing receptor
        receptor_fn=os.path.join(receptor_dir,self.allele+".pdb")
        if Path(receptor_fn).is_file():
            if not overwrite:
                db_print(f"Receptor file {os.path.basename(receptor_fn)} located in {receptor_dir}",mute=self.mute)
                self.receptor=receptor_fn
                return True
            else:
                notify().warn(f"Prexising file {receptor_fn} found and will be overwritten.")

        # Check and make sure alphafold dependencies are present.
        IO_DIR=receptor_dir
        FASTA=os.path.join(IO_DIR,self.allele+".fasta")

        # Check if specified alphafold directories exist.
        if not Path(AF2_MINICONDA).is_dir() or not Path(AF2_DATADIR).is_dir() or not Path(AF2_REPO).is_dir():
            notify().error(f"One or more alphafold installation directories do not exist.")
            return False

        # Make IO directory if it does not exist
        if not Path(IO_DIR).is_dir():
            print(f"Creating directory {IO_DIR}")
            Path(IO_DIR).mkdir(parents=True,exist_ok=True)

        # Make the allele fasta file
        with open(FASTA,"w") as f:
            f.write(f">{self.allele}\n")
            f.write(f"{self.sequence}")

        # Run alpha fold
        print(f"Predicting structure of {self.allele} with AlphaFold2...")
        args=f"source {AF2_MINICONDA}/bin/activate af2;python {AF2_REPO}/run_alphafold.py --fasta_paths={FASTA} --max_template_date=9999-12-31 --data_dir={AF2_DATADIR} --output_dir={IO_DIR} --uniref90_database_path={AF2_DATADIR}/uniref90/uniref90.fasta --mgnify_database_path={AF2_DATADIR}/mgnify/mgy_clusters.fa --uniclust30_database_path={AF2_DATADIR}/uniclust30/uniclust30_2018_08/uniclust30_2018_08 --bfd_database_path={AF2_DATADIR}/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt --pdb70_database_path={AF2_DATADIR}/pdb70/pdb70 --template_mmcif_dir={AF2_DATADIR}/pdb_mmcif/mmcif_files --obsolete_pdbs_path={AF2_DATADIR}/pdb_mmcif/obsolete.dat"
        subprocess.run(args, shell=True)

        # Extract the best model with the best pLDDT score (ranked_0.pdb)
        # Rename the file and cleanup
        receptor_best=os.path.join(IO_DIR,self.allele,"ranked_0.pdb")

        if Path(receptor_best).is_file():
            os.rename(receptor_best,receptor_fn)
        else:
            notify().error(f"{receptor_best} not found! Did alpha fold execute correctly?")
            return False

        shutil.rmtree(Path(os.path.dirname(receptor_best)))
        os.remove(FASTA)
        print(f"{self.allele} structure saved to {receptor_fn}")
        self.receptor=receptor_fn

        return True

    def get_peptide_template(self, query_sequence, method="best", cutoff=0, omit=[]):
        # Method to retrieve a structure from the database whose peptide backbone sequence matchest that of the query. Returns the PDB filename in <database>/templates that corresponds to the matching structure. If execution fails, returns false.
        # Description of method variables:
        # query_sequence: the sequence we are looking to find a template for
        # method: The method to perform the match (string). Options include:
        #  "best": [default] Finds the best matching template by alignment similarity score using a BLOSUM62 matrix for AA similarity
        #  "worst": As above, but returns the template with the worst score
        #  "bestabove": Finds the best matching template by % identity above a threshold given by the variable 'cutoff'
        #  "worstbelow": Finds the worst matching template by % identity below a threshold given by the variable 'cutoff'
        # cutoff: Set a value between 0 and 1 that indicates a threshold for sequence identity for "bestabove" and "worstbelow" methods.
        # omit: A list of PDB templates to omit from template selection (4-character PDB codes). If "self" is included in the list, any template with a 100% matching sequence will be ignored.

        methods=["best","worst","bestabove","worstbelow"] # List of allowed values for the method variable

        # Do some basic error checking of our inputs:
        # Does the database info file exist
        if not Path(os.path.join(self.locate,"database.info")).is_file():
            notify().error(f"Database file {os.path.join(self.locate,'database.info')} does not exist! Run MHCdatabase().build() to create, or specify database location of the instance with the attribute 'locate'")
            return False

        # Does the allele set on the database instance have an available sequence?
        allele_list_info_fn=os.path.join(self.locate,"build","allele_list.info")
        if not Path(allele_list_info_fn).is_file():
            notify().error(f"Complete allele sequence list {allele_list_info_fn} not located. Call MHCdatabase().build() to rebuild database, or check MHCdatabase().locate to ensure paths are correct")
        else:
            allele_list_info=pd.read_csv(allele_list_info_fn)
            if self.allele not in allele_list_info["Allele_Name"].unique().tolist():
                notify().error(f"Allele {self.allele} not located in database!")
                return False

        # Make sure the instance has MHC templates set
        if self.templates==None or len(self.templates)==0:
            self.set_mhc_templates()

        if method not in methods:
            notify().warn(f"{method} is an invalid method. Options include: {', '.join(methods)}. Setting to default 'best'")
            method="best" # Set methods to default value if user makes an invalid selection
        elif (method=="bestabove" or method=="worstbelow") and not 0<=cutoff<=1:
            bad_cutoff=cutoff
            if method=="bestabove":
                cutoff=0
            else:
                cutoff=1
            notify().warn(f"{bad_cutoff} is an invalid threshold (must be between 0 and 1). Setting to default of {cutoff}...")
        struct_data=pd.read_csv(os.path.join(self.locate,"database.info")) # Read in our database data file

        found_templates=False
        if self.templates==None:
            self.templates=[self.allele]

        # Ensure we don't accidentally count placeholder 3-letter codes for sequences with a NCAA

        for allele in self.templates:
            db_records=struct_data.loc[struct_data["MHC_Allele"]==allele].copy()
            db_records["Seq_Length"]=db_records["Epitope_Description"].apply(lambda x:len(x))
            if "self" in omit: #Define our PDBs to omit if the user requests omitting identical peptides
                omit_self=db_records["PDB_ID"].loc[db_records["Epitope_Description"]==query_sequence].tolist()
            else:
                omit_self=["NONE"] # Arbitrary value that will never equal "equal_seq_pdbs"
            equal_seq_lengths=db_records["Seq_Length"].loc[db_records["Seq_Length"]==len(query_sequence)].any()
            equal_seq_pdbs=db_records["PDB_ID"].loc[db_records["Epitope_Description"]==query_sequence].tolist()
            # Proceed with template selection from this allele only if:
            #    (1) There exists at least one template with the same length as the query sequence, and
            #    (2) There exists at least one equal length template that is not in omit_self
            if omit_self != equal_seq_pdbs and equal_seq_lengths:
                print(f"Found acceptable peptide templates using allele {allele}")
                found_templates=True
                break
        if not found_templates:
            notify().error(f"No suitable peptide backbone templates found for {query_sequence} in the MHC database. Unable to thread peptide and generate starting model. Consider using FlexPepDock ab-initio.")
            return False

        template_seqs=db_records["Epitope_Description"].tolist()

        # Append our list of PDBs to omit with the one containing the query sequence if requested by user
        if "self" in omit:
            omit.extend(db_records["PDB_ID"].loc[db_records["Epitope_Description"]==query_sequence].tolist())
            omit.remove("self")
            if len(omit)!=0:
                print(f"Omitting PDB templates {' '.join(omit)}")
        omit=[x.lower() for x in omit]

        # Use BLOSUM62 matrix for amino acid substitutions in calculating alignment score
        matrix = substitution_matrices.load("BLOSUM62")

        # Set starting thresholds for methods that score alignments
        if method=="best":
            thresh=-10000
        elif method=="worst":
            thresh=10000
        else:
            thresh=cutoff
        no_match_found=True
        scores=[]

        print("{:^20}|{:^20}|{:^10}|{:^10}".format("Query sequence","Database match","PDB","Score"))
        for record in template_seqs:
            # Do an alignment with the next record (for now, exclude matches where the template sequence is shorter than the input sequence)
            tmp_pdb=db_records["PDB_ID"].loc[db_records["Epitope_Description"]==record].iloc[0]
            # First check: does the query sequence equal the template sequence length, and is the template not excluded from comparison?
            if len(record)==len(query_sequence) and tmp_pdb.lower() not in omit:
                # If not then move on to the next step on a per method basis
                if method=="best" or method=="worst":
                    tmp_alignments = pairwise2.align.globalds(query_sequence, record, matrix, -10, -0.5) # Set gap open and extension penalties here. BLOSUM62 is used to score amino acid matches/mismatches
                    for a in tmp_alignments:
                        # For each alignment, find the lowest score and save it if less than current best score (or reverse if method set to "best")
                        scores.append(a.score)
                        if (method=="worst" and a.score<thresh) or (method=="best" and a.score>thresh):
                            best_sequence=record
                            best_alignment=a
                            thresh=a.score
                            best_pdb=tmp_pdb
                            print(f"{query_sequence:^20}|{best_sequence:^20}|{best_pdb:^10}|{thresh:^10}")
                            if no_match_found:
                                no_match_found=False
                else:
                    matching_res_count=0
                    for i,aa in enumerate(query_sequence):
                        if aa==record[i]:
                            matching_res_count+=1
                    percent_match=matching_res_count/len(query_sequence)
                    scores.append(percent_match)
                    if (method=="bestabove" and percent_match>thresh) or (method=="worstbelow" and percent_match<thresh):
                        best_sequence=record
                        thresh=percent_match
                        best_pdb=tmp_pdb
                        if no_match_found:
                            no_match_found=False
        if no_match_found:
            if len(scores)==0:
                bestscore="None"
            elif method=="best" or method=="bestabove":
                bestscore=max(scores)
            else:
                bestscore=min(scores)
            notify().warn("No satisfactory alignment found for input sequence {}.\nRun aborted.\nAdjust thresh to a value less than an acceptable minimum score (Best alignment score found is {}, method chosen is {})".format(query_sequence, bestscore, method))
            return False

        print("\nAlignment:")
        print("{}    Query sequence".format(query_sequence))
        print("{}    Database match".format(best_sequence))
        best_pdb_fn = os.path.abspath(os.path.join(self.locate,"templates",best_pdb+".pdb"))

        # Make sure we have the matching PDB for threading the sequence, otherwise abort
        if not os.path.isfile(best_pdb_fn):
            notify().error("Matching PDB file {} not found in database".format(best_pdb))
            return False
        else:
            print("\nMatching PDB found in database: {}".format(best_pdb))

        return best_pdb

    def help(self):
        # Print the docs and exit
        subprocess.run(["clear"])
        print(help_msg())
        return
